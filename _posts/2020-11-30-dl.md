---
date: 2020-11-30  
title: "DL 기초, 딥러닝의 구조 및 학습과정, 용어 정리"  
categories:
  - data science  
tags: 
  - deeplearning  
toc: true  
toc_sticky: true 
---
데이터 -> (모델 -> logit -> loss -> optm -> 모델 : 반복) -> result


### DATA
- 학습 시키기 위한 데이터. 이 데이터가 모델에 들어감
- 데이터가 생성되고, 데이터에 Transform 변형을 준다거나 모델에 들어가기 전에 데이터 전처리가 들어감
- 이 때, 들어갈 때는 Batch로 만들어서 Model에 넣어줌

### Model
- LeNet, AlexNet, VGG, ResNet 등 다양하게 설계된 모델
- Convolution layer, Pooling 등 다양한 Layer층들로 구성
- 이 모델 안에 학습 파라미터가 있고, 이 모델이 학습하는 대상

### Prediction/Logit
#### [0.15, 0.3, 0.2, 0.25, 0.1].  
- 각 Class 별로 예측한 값
- 여기서 가장 높은 값이 모델이 예상하는 값
#### [0.0, 1.0, 0.0, 0.0, 0.0].  
- 위의 숫자가 정답이라고 할 때 얼마나 틀렸는지 얼마나 맞았는지 확인 가능

### Loss/ Cost
- 예측한 값과 정답과 비교해서 얼마나 틀렸는지 확인
- Cross Entropy 등 다양한 Loss Function 들이 있음
- 이 때 계산을 통해 나오는 값이 Loss (Cost, Cost Value 등)이라고 불림
- 이 Loss는 ‘얼마나 틀렸는지’를 말하며 이 값을 최대한 줄이는 것이 학습의 과정

### Optimization
- 앞에서 얻은 Loss 값을 최소하 하기 위해 기울기를 받아 최적화된 Variable 값들로 반환
- 이 반환된 값이 적용된 모델은 바로 전에 돌렸을 때의 결과보다 더 나아지게 됨
- 이 때 바로 최적화된 값 만큼 바로 움직이는 것이 아닌 Learning Rate 만큼 움직인 값이 적용
